# ================================================================
# ğŸŒ TAAA Semantic Extractor
#  - Compatible with OpenAI Python SDK v1.x+
#  - FastAPI backend for Render deployment
#  - Multilingual semantic keyword extraction (auto-detect)
# ================================================================

from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse, HTMLResponse
import pandas as pd
from openai import OpenAI
import tempfile
import os

# ----------------------------
# ğŸ”§ Initialize
# ----------------------------
app = FastAPI(
    title="TAAA Semantic Extractor",
    description="Upload abstracts and extract 10 semantic keywords via GPT-4o-mini (multilingual auto-detect)",
    version="2.0.0"
)

# Instantiate OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ----------------------------
# ğŸ  Home route
# ----------------------------
@app.get("/", response_class=HTMLResponse)
def home():
    try:
        html = open("index.html", "r", encoding="utf-8").read()
        return HTMLResponse(content=html)
    except Exception as e:
        return HTMLResponse(content=f"<h3>Error loading page:</h3><p>{e}</p>")


# ----------------------------
# ğŸ“¤ CSV upload route
# ----------------------------
@app.post("/analyze_csv")
async def analyze_csv(file: UploadFile = File(...)):
    try:
        df = pd.read_csv(file.file)
    except Exception as e:
        return {"error": f"âŒ Unable to read CSV: {e}"}

    if "abstract" not in df.columns:
        return {"error": "Missing 'abstract' column. Please include a column named 'abstract'."}

    df["keywords"] = df["abstract"].apply(lambda x: extract_keywords(str(x)))

    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".csv")
    df.to_csv(tmp.name, index=False, encoding="utf-8-sig")

    return FileResponse(
        tmp.name,
        media_type="text/csv",
        filename="taaa_keywords.csv"
    )


# ----------------------------
# ğŸ§  Keyword extraction function
# ----------------------------
def extract_keywords(text: str) -> str:
    """Call GPT-4o-mini to extract 10 representative semantic keywords."""
    if not text or pd.isna(text):
        return ""

    prompt = (
        "è«‹æ ¹æ“šä»¥ä¸‹æ‘˜è¦å…§å®¹ï¼Œèƒå– 10 å€‹å…·èªç¾©ä»£è¡¨æ€§çš„å­¸è¡“é—œéµè©ï¼Œ"
        "å¯ç‚ºç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡ï¼ˆä¾åŸæ–‡èªè¨€è‡ªå‹•åˆ¤æ–·ï¼‰ï¼Œä¸¦ç”¨é “è™Ÿï¼ˆã€ï¼‰åˆ†éš”ã€‚"
        "è‹¥æ‘˜è¦ç‚ºéä¸­è‹±æ–‡èªè¨€ï¼ˆå¦‚æ—¥æ–‡ã€è¥¿ç­ç‰™æ–‡ã€æ³•æ–‡ç­‰ï¼‰ï¼Œè«‹è‡ªå‹•ä»¥ç›¸åŒèªè¨€å›è¦†ã€‚\n\n"
        f"{text}"
    )

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        return f"Error: {e}"


# ----------------------------
# ğŸš€ Local dev entry point
# ----------------------------
if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
